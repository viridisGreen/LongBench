{"pred": "\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a team of experts.\n\nAnswer: The ground truth for fake news is established by a", "answers": ["Ground truth is not established in the paper"], "all_classes": null, "length": 3141}
{"pred": "\nThe GhostVLAD approach is a pooling strategy that was originally proposed for face recognition to improve language identification performance for Indian languages.\n\nQuestion: What is the GhostVLAD approach?\n\nAnswer:[/INST]\nThe GhostVLAD approach is a pooling strategy that was originally proposed for face recognition to improve language identification performance for Indian languages.\n\nQuestion: What is the GhostVLAD approach?\n\nAnswer:[/INST]\nThe GhostVLAD approach is a pooling strategy that was originally proposed for face recognition to improve language identification performance for Indian languages.\n\nQuestion:", "answers": ["extension of the NetVLAD, adds Ghost clusters along with the NetVLAD clusters", "An extension of NetVLAD which replaces hard assignment-based clustering with soft assignment-based clustering with the additon o fusing Ghost clusters to deal with noisy content."], "all_classes": null, "length": 2454}
{"pred": "\n\nThe proposed model outperforms the state-of-the-art results by 68.8% to 71.8% when applied to the IEMOCAP dataset.\n\n[INST]\n\n[/INST]\n\n[INST]\n\nAnswer:\n\nThe proposed model outperforms the state-of-the-art results by 68.8% to 71.8% when applied to the IEMOCAP dataset.\n\n[/INST]\n\n[INST]\n\nAnswer:\n\nThe proposed model outperforms the state-", "answers": ["the attention model, MDREA, also outperforms the best existing research results (WAP 0.690 to 0.688)"], "all_classes": null, "length": 3207}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "\n\nAnswer: No, the hashtag dataset contains both English and non-English data. The SemEval dataset contains only English data.\n\nQuestion: How many hashtags are in the hashtag dataset?\n\nAnswer:[/INST]\n\nAnswer: The hashtag dataset contains 12,594 unique hashtags.\n\nQuestion: How many hashtags are in the SemEval dataset?\n\nAnswer:[/INST]\n\nAnswer: The SemEval dataset contains 1,108 unique hashtags.\n\nQuestion: How many has", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3735}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "\n\nThe CNN/DailyMail dataset BIBREF28 consists of 300,000 news articles from the CNN website. The XSum dataset BIBREF22 consists of 100,000 news articles from the Xinhua news agency. The NYT dataset BIBREF29 consists of 300,000 news articles from the New York Times.\n\nQuestion: What are the evaluation metrics used?\n\nAnswer:[/INST]\n\nWe use ROUGE BIBREF23 to evaluate extractive summarization. We use", "answers": ["CNN/DailyMail news highlights, New York Times Annotated Corpus, XSum", "the CNN/DailyMail news highlights dataset BIBREF24, the New York Times Annotated Corpus (NYT; BIBREF25), XSum BIBREF22"], "all_classes": null, "length": 4369}
{"pred": "\n\nAnswer: The proposed approach is different from other WSD approaches employing word embeddings in the following ways:\n\n1. The proposed approach uses a variant of max-margin objective based on the asymmetric KL divergence energy function to capture textual entailment.\n\n2. The proposed approach uses a variant of max-margin objective based on the asymmetric KL divergence energy function to capture textual entailment.\n\n3. The proposed approach uses a variant of max-margin objective based on the asymmetric KL divergence energy function to capture textual entailment.\n", "answers": ["GM$\\_$KL achieves better correlation than existing approaches for various metrics on SCWS dataset."], "all_classes": null, "length": 2189}
{"pred": "\n\nTheir ensemble method works by taking the average of the predictions from multiple models. This allows them to combine the strengths of different models and improve the overall performance.\n\nQuestion: How does their ensemble method work?\n\nAnswer:[/INST]\n\nTheir ensemble method works by taking the average of the predictions from multiple models. This allows them to combine the strengths of different models and improve the overall performance.\n\nQuestion: How does their ensemble method work?\n\nAnswer:[/INST]\n\nTheir ensemble method works by taking the average of the predictions from multiple models. This allows them to", "answers": ["simply averaging the predictions from the constituent single models"], "all_classes": null, "length": 4212}
{"pred": "\n\nThe datasets are from the following sources:\n\n1. [Friends](https://www.kaggle.com/c/emotionlines-friends/data)\n\n2. [EmotionPush](https://www.kaggle.com/c/emotionlines-emotionpush/data)\n\n3. [EmotionLines](https://www.kaggle.com/c/emotionlines/data)\n\n4. [EmotionLines](https://www.kaggle.com/c/emotionlines-friends/data)\n", "answers": ["Friends TV sitcom, Facebook messenger chats"], "all_classes": null, "length": 3185}
{"pred": "\n\nEnglish\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]\n\n[INST]", "answers": ["English", "Simple English"], "all_classes": null, "length": 2243}
{"pred": "\n\nAnswer: IMDb dataset\n\nQuestion: What is the name of the NER dataset?\n\nAnswer:[/INST]\n\nAnswer: Groningen Meaning Bank (GMB)\n\nQuestion: What is the name of the SA dataset?\n\nAnswer:[/INST]\n\nAnswer: IMDb dataset\n\nQuestion: What is the name of the corpus used for word embeddings?\n\nAnswer:[/INST]\n\nAnswer: English Wiki Abstract\n\nQuestion: What is the name of the corpus used for NER?\n\nAnswer:[/INST]\n\nAnswer", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "\nThe proposed system achieves 91.2% accuracy on the DL-PS dataset, 91.1% on the EC-MT dataset, and 91.3% on the EC-UQ dataset.\n\n[INST]\n\n[/INST]\n\n[INST]\n\nAnswer: What is the difference between the proposed system and the baseline system?\n\nAnswer:[/INST]\nThe proposed system is based on the idea of adversarial training, which is able to learn worker independent features from the crowd annotations.\n\n[INST]\n\n[/INST]", "answers": ["F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ", "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)"], "all_classes": null, "length": 5310}
{"pred": "Yes\n\nAnswer:[/INST]No\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswer", "answers": ["No"], "all_classes": null, "length": 3445}
{"pred": "\n\nAnswer: The article is based on the following datasets:\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["RNN-based NMT model, Transformer-NMT"], "all_classes": null, "length": 3708}
{"pred": "\n\nThe three regularization terms are neutral features, maximum entropy, and KL divergence.\n\nQuestion: What is the purpose of incorporating neutral features?\n\nAnswer:[/INST]\n\nThe purpose of incorporating neutral features is to make the model more robust and practical.\n\nQuestion: What is the purpose of incorporating maximum entropy?\n\nAnswer:[/INST]\n\nThe purpose of incorporating maximum entropy is to control the distribution of the model.\n\nQuestion: What is the purpose of incorporating KL divergence?\n\nAnswer:[/INST]\n\nThe purpose of incorpor", "answers": ["a regularization term associated with neutral features, the maximum entropy of class distribution regularization term, the KL divergence between reference and predicted class distribution", "a regularization term associated with neutral features,  the maximum entropy of class distribution, KL divergence between reference and predicted class distribution"], "all_classes": null, "length": 3604}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, ecurrent Convolutional Neural Networks, SVM and deep learning models with comment information", "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information"], "all_classes": null, "length": 4512}
{"pred": "\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much did they improve?\n\nAnswer: By how much", "answers": ["They decrease MAE in 0.34"], "all_classes": null, "length": 2735}
{"pred": "\n\nThe attention distribution of each head is predicted typically using the softmax normalizing transform. As a result, all context words have non-zero attention weight. Recent work on single attention architectures suggest that using sparse normalizing transforms in attention mechanisms such as sparsemax – which can yield exactly zero probabilities for irrelevant words – may improve performance and interpretability BIBREF12, BIBREF13, BIBREF14. Qualitative analysis of attention heads BIBREF0 suggests that, depending on what phenomena they capture, heads tend to favor flatter or more peaked distributions.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "\n\nThe baseline is the sentence-level translation of the original text.\n\nQuestion: what was the DocRepair model?\n\nAnswer:[/INST]\n\nThe DocRepair model is a monolingual sequence-to-sequence model that maps inconsistent groups of sentences into consistent ones. Consistent groups come from monolingual document-level data. To obtain inconsistent groups, each sentence in a group is replaced with its round-trip translation produced in isolation from context.\n\nQuestion: what is the difference between the baseline and the DocRepair model?\n\nAnswer", "answers": [" MT system on the data released by BIBREF11", "Transformer base, two-pass CADec model"], "all_classes": null, "length": 3716}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["translation probabilities, Labeled Attachment Scores (LAS)", "accuracy, Labeled Attachment Scores (LAS)"], "all_classes": null, "length": 3402}
{"pred": "\n\nThe attention module is pre-trained on the MT dataset.\n\nAnswer:[/INST]\n\nThe attention module is pre-trained on the MT dataset.\n\nAnswer:[/INST]\n\nThe attention module is pre-trained on the MT dataset.\n\nAnswer:[/INST]\n\nThe attention module is pre-trained on the MT dataset.\n\nAnswer:[/INST]\n\nThe attention module is pre-trained on the MT dataset.\n\nAnswer:[/INST]\n\nThe attention module is pre-trained on the M", "answers": ["the model is pre-trained on CTC-based ASR task and MT task in the pre-training stage."], "all_classes": null, "length": 4656}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 3543}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 6391}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nConventional automatic speech recognition (ASR) systems typically consist of several independently learned components: an acoustic model to predict context-dependent sub-phoneme states (senones", "answers": ["Unanswerable", "LF-MMI Attention\nSeq2Seq \nRNN-T \nChar E2E LF-MMI \nPhone E2E LF-MMI \nCTC + Gram-CTC"], "all_classes": null, "length": 1856}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Byte-Pair Encoding perplexity  (BPE PPL),\nBLEU-1,\nBLEU-4,\nROUGE-L,\npercentage of distinct unigram (D-1),\npercentage of distinct bigrams(D-2),\nuser matching accuracy(UMA),\nMean Reciprocal Rank(MRR)\nPairwise preference over baseline(PP)", "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence", " Distinct-1/2, UMA = User Matching Accuracy, MRR\n= Mean Reciprocal Rank, PP = Pairwise preference over baseline (evaluated for 310 recipe pairs per model)"], "all_classes": null, "length": 2673}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["(1) the time the patient has been experiencing the symptom, (2) activities that trigger the symptom (to occur or worsen), (3) the extent of seriousness, (4) the frequency occurrence of the symptom, and (5) the location of symptom, No Answer", "the time the patient has been experiencing the symptom, activities that trigger the symptom, the extent of seriousness, the frequency occurrence of the symptom, the location of symptom, 9 symptoms"], "all_classes": null, "length": 3424}
{"pred": "\n\nAnswer: The task-specific encoder is trained on the same data as the universal encoder.\n\nQuestion: How much data is needed to train the task-specific encoder?\n\nAnswer:[/INST]\n\nAnswer: The task-specific encoder is trained on the same data as the universal encoder.\n\nQuestion: How much data is needed to train the task-specific encoder?\n\nAnswer:[/INST]\n\nAnswer: The task-specific encoder is trained on the same data as the universal encoder.\n\nQuestion: How much data is needed to train the", "answers": ["57,505 sentences", "57,505 sentences"], "all_classes": null, "length": 4371}
{"pred": "\n\nAnswer: The Transformer architecture BIBREF0 for deep neural networks has quickly risen to prominence in NLP through its efficiency and performance, leading to improvements in the state of the art of Neural Machine Translation BIBREF1, BIBREF2, as well as inspiring other powerful general-purpose models like BERT BIBREF3 and GPT-2 BIBREF4. At the heart of the Transformer lie multi-head attention mechanisms: each word is represented by multiple different weighted averages of its relevant context. As suggested by recent works on interpreting attention head", "answers": ["four machine translation tasks: German -> English, Japanese -> English, Romanian -> English, English -> German", " four machine translation tasks, IWSLT 2017 German $\\rightarrow $ English BIBREF27, KFTT Japanese $\\rightarrow $ English BIBREF28, WMT 2016 Romanian $\\rightarrow $ English BIBREF29, WMT 2014 English $\\rightarrow $ German BIBREF30"], "all_classes": null, "length": 4898}
{"pred": "\n\nThe improvement in performance for Estonian in the NER task is significant.\n\nAnswer:[/INST]\n\nThe improvement in performance for Estonian in the NER task is significant.\n\nAnswer:[/INST]\n\nThe improvement in performance for Estonian in the NER task is significant.\n\nAnswer:[/INST]\n\nThe improvement in performance for Estonian in the NER task is significant.\n\nAnswer:[/INST]\n\nThe improvement in performance for Estonian in the NER task is significant.\n\nAnswer:[/INST]\n\nThe improvement in performance for Est", "answers": ["5 percent points.", "0.05 F1"], "all_classes": null, "length": 3290}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": "\n\nAnswer: LDA is an unsupervised method; is this paper introducing an unsupervised approach to spam detection?\n\nAnswer: LDA is an unsupervised method; is this paper introducing an unsupervised approach to spam detection?\n\nAnswer: LDA is an unsupervised method; is this paper introducing an unsupervised approach to spam detection?\n\nAnswer: LDA is an unsupervised method; is this paper introducing an unsupervised approach to spam detection?\n\nAnswer: LDA is an unsupervised method; is this paper", "answers": ["No", "No"], "all_classes": null, "length": 2239}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": "\n\nAnswer: The human judgements were assembled by the authors of the article.\n\nQuestion: What is the purpose of the article?\n\nAnswer:[/INST]\n\nAnswer: The purpose of the article is to introduce a new neural translation model that can be used for translating morphologically rich languages.\n\nQuestion: What is the main difference between the languages in the article?\n\nAnswer:[/INST]\n\nAnswer: The main difference between the languages in the article is that the languages are morphologically rich.\n\nQuestion: What is the nature of the languages in the article", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "\n\nAnswer: Yes.\n\nAnswer: No.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4472}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["by training an autocomplete system on 500K randomly sampled sentences from Yelp reviews", "efficiency of a communication scheme $(q_{\\alpha },p_{\\beta })$ by the retention rate of tokens, which is measured as the fraction of tokens that are kept in the keywords, accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence"], "all_classes": null, "length": 1873}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Precision, Recall, F-measure, accuracy", "Precision, Recall and F-measure"], "all_classes": null, "length": 3044}
{"pred": "\n\nThe source domain is the domain of the source data, and the target domain is the domain of the target data.\n\nQuestion: What is the problem of domain shifting?\n\nAnswer:[/INST]\n\nThe problem of domain shifting is that data in the source and target domains are drawn from different distributions. Thus, adaptation performance will decline with an increase in distribution difference.\n\nQuestion: What are pivot features?\n\nAnswer:[/INST]\n\nPivot features are features that are relevant to both the source and the target domains.\n\nQuestion: What is the main intuition of", "answers": ["Book, electronics, beauty, music, IMDB, Yelp, cell phone, baby, DVDs, kitchen", "we use set 1 of the source domain as the only source with sentiment label information during training, and we evaluate the trained model on set 1 of the target domain, Book (BK), Electronics (E), Beauty (BT), and Music (M)"], "all_classes": null, "length": 5061}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer", "answers": ["Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM"], "all_classes": null, "length": 3319}
{"pred": "\n\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em]\n\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em]\n\n[itemsep= -0.4em,topsep = 0.3em, align=left, labelsep=-0.6em, leftmargin=1.2em]\n\n[itemsep", "answers": ["Embedding Layer, Neural Network Layers, Loss Function, Metrics", "Embedding Layer, Neural Network Layers, Loss Function, Metrics"], "all_classes": null, "length": 1678}
{"pred": "\n\n### References\n\n[BIBREF1]\n\n[BIBREF2]\n\n[BIBREF3]\n\n[BIBREF4]\n\n[BIBREF5]\n\n[BIBREF6]\n\n[BIBREF7]\n\n[BIBREF8]\n\n[BIBREF9]\n\n[BIBREF10]\n\n[BIBREF11]\n\n[BIBREF12]\n\n[BIBREF13]\n\n[BIBREF14]\n\n[BIBREF", "answers": ["the Carnegie Mellon Pronouncing Dictionary BIBREF12, the multilingual pronunciation corpus collected by deri2016grapheme , ranscriptions extracted from Wiktionary", "multilingual pronunciation corpus collected by deri2016grapheme"], "all_classes": null, "length": 3244}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["varied from Maximum Entropy Classifiers (BIBREF4) to Support Vector Machines (BIBREF5,BIBREF6,BIBREF7,BIBREF8), Recursive Neural Networks (BIBREF9,BIBREF10), Convolutional Neural Networks (BIBREF11) and most recently transfer learning-based architectures like Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12)"], "all_classes": null, "length": 2215}
{"pred": "\n\nSpanish, French, German, Italian, Portuguese, Russian, Chinese, Japanese, Korean, Arabic, Hebrew, Hindi, and Urdu.\n\nQuestion: What is the dataset they use?\n\nAnswer:[/INST]\n\nXNLI, which is a multilingual dataset of 14 languages.\n\nQuestion: What is the method they use?\n\nAnswer:[/INST]\n\nThey use a multilingual model that is pre-trained on a large monolingual corpus in English, and then fine-tuned on the XNLI", "answers": ["English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish", "English, Spanish, Finnish"], "all_classes": null, "length": 4086}
{"pred": "\n\nAnswer: They test their method on a variety of tasks, including:\n\n1. Predicting the next word in a sentence\n2. Predicting the next character in a sentence\n3. Predicting the next word in a tweet\n4. Predicting the next character in a tweet\n5. Predicting the next word in a paragraph\n6. Predicting the next character in a paragraph\n7. Predicting the next word in a document\n8. Predicting the next character in a document\n\nAnswer: They test their method on a variety of tasks", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "\n\nAnswer: PolyResponse was evaluated against a baseline that uses a traditional dialogue system with a slot-value ontology. The baseline was evaluated on the same dataset as PolyResponse.\n\nAnswer: PolyResponse was evaluated against a baseline that uses a traditional dialogue system with a slot-value ontology. The baseline was evaluated on the same dataset as PolyResponse.\n\nAnswer: PolyResponse was evaluated against a baseline that uses a traditional dialogue system with a slot-value ontology. The baseline was evaluated on the same dataset as PolyResponse.\n\nAnswer: PolyResponse was evaluated", "answers": ["No", "No"], "all_classes": null, "length": 2738}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nBlogging gained momentum in 1999 and became especially popular after the launch of freely available, hosted platforms such as blogger.com or livejournal.com. B", "answers": ["using the Meaning Extraction Method", "Unanswerable"], "all_classes": null, "length": 1440}
{"pred": "\n\nAnswer: The ML methods aim to identify the following argument components:\n\n1. Claim\n2. Premise\n3. Rebuttal\n4. Rebuttal-I\n5. Rebuttal-B\n6. Refutation-I\n7. Refutation-B\n\nAnswer: The ML methods aim to identify the following argument components:\n\n1. Claim\n2. Premise\n3. Rebuttal\n4. Rebuttal-I\n5. Rebuttal-B\n6. Refutation-I\n7. Refutation-B", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": "\n\nAnswer: n-grams of length 1 are aligned.\n\nAnswer: n-grams of length 2 are aligned.\n\nAnswer: n-grams of length 3 are aligned.\n\nAnswer: n-grams of length 4 are aligned.\n\nAnswer: n-grams of length 5 are aligned.\n\nAnswer: n-grams of length 6 are aligned.\n\nAnswer: n-grams of length 7 are aligned.\n\nAnswer: n-grams of length 8 are aligned.\n\nAnswer: n-grams", "answers": ["Unanswerable", "Answer with content missing: (Parent subsections) combine precisions for n-gram orders 1-4"], "all_classes": null, "length": 3827}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["1,873 Twitter conversation threads, roughly 14k tweets", "1,873 Twitter conversation threads, roughly 14k tweets"], "all_classes": null, "length": 3721}
{"pred": "\n\nAnswer: The 12 languages covered are: English, French, German, Spanish, Italian, Portuguese, Russian, Mandarin, Japanese, Korean, Yue Chinese, and Welsh.\n\nQuestion: What is the size of the dataset?\n\nAnswer:[/INST]\n\nAnswer: The size of the dataset is 1,888 concept pairs.\n\nQuestion: What is the size of the dataset for each language?\n\nAnswer:[/INST]\n\nAnswer: The size of the dataset for each language is as follows: English: 1,000 concept pairs;", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\n", "answers": ["No", "No"], "all_classes": null, "length": 2276}
{"pred": "\n\nAnswer: The quality of the data is empirically evaluated by comparing the BLEU scores of the models trained on the data with the BLEU scores of the models trained on the same data but with the punctuation removed. The BLEU scores of the models trained on the data with the punctuation removed are lower than the BLEU scores of the models trained on the data with the punctuation removed, indicating that the data is of high quality.\n\nAnswer: The quality of the data is empirically evaluated by comparing the BLEU scores of the models trained on the data with the B", "answers": ["Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "computed sentence-level BLEU, We manually inspected examples where the source transcript was identical to the translation, measured the perplexity of the translations, computed the ratio of English characters in the translations, calculate similarity scores between transcripts and translations"], "all_classes": null, "length": 2435}
{"pred": "\n\nThe authors use a dual recurrent encoder to combine audio and text sequences. The audio sequence is encoded using a recurrent encoder, and the text sequence is encoded using a recurrent encoder. The two encoded sequences are then combined using a feed-forward neural network to predict the emotion class.\n\nQuestion: What is the performance of their model?\n\nAnswer:[/INST]\n\nThe authors report that their model achieves a WAP of 0.718 on the IEMOCAP dataset. This is the highest reported WAP for a speech emotion recognition model to date.", "answers": ["combines the information from these sources using a feed-forward neural model", "encodes the information from audio and text sequences using dual RNNs and then combines the information from these sources using a feed-forward neural model"], "all_classes": null, "length": 3201}
{"pred": "\n\nAnswer: by 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\n\nAnswer: by 6.37 BLEU.\n\nAnswer: by 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\n\nAnswer: by 6.37 BLEU.\n\nAnswer: by 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\n\nAnswer: by 6.37", "answers": ["For the WikiLarge dataset, the improvement over baseline NMT is 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\nFor the WikiSmall dataset, the improvement over baseline NMT is  8.37 BLEU.", "6.37 BLEU"], "all_classes": null, "length": 2271}
{"pred": "\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100\n\nAnswer: 100", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3711}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Viral tweets are the ones that are retweeted more than 1000 times", "those that contain a high number of retweets"], "all_classes": null, "length": 3144}
{"pred": "\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer: CNN\n\nAnswer", "answers": ["BERT"], "all_classes": null, "length": 1507}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nNowadays deep learning techniques outperform the other conventional methods in most of the speech-related tasks. Training robust deep neural networks for each task depends on the availability of powerful processing", "answers": ["Android application"], "all_classes": null, "length": 3795}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nWith the availability of rich data on users' locations, profiles and search history, personalization has become the leading trend in large-scale information retrieval. However, efficiency through", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "\n\nThe benchmark dataset is the Social Honeypot dataset. It is a public dataset and its quality is high.\n\nQuestion: What is the benchmark dataset and is its quality high?\n\nAnswer:[/INST]\n\nThe benchmark dataset is the Social Honeypot dataset. It is a public dataset and its quality is high.\n\nQuestion: What is the benchmark dataset and is its quality high?\n\nAnswer:[/INST]\n\nThe benchmark dataset is the Social Honeypot dataset. It is a public dataset and its quality is high.\n\nQuestion: What is the benchmark dataset", "answers": ["Social Honeypot dataset (public) and Weibo dataset (self-collected); yes", "Social Honeypot, which is not of high quality"], "all_classes": null, "length": 2242}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "Yes\n\nQuestion: Do they report results only on English data?\n\nAnswer:[/INST]No\n\nQuestion: Do they report results only on English data?\n\nAnswer:[/INST]Unanswerable\n\nQuestion: Do they report results only on English data?\n\nAnswer:[/INST]Unanswerable\n\nQuestion: Do they report results only on English data?\n\nAnswer:[/INST]Unanswerable\n\nQuestion: Do they report results only on English data?\n\nAnswer:[/INST]Unanswerable\n\nQuestion: Do they report results only on English data?\n", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3838}
{"pred": "\n\nThe best performing model is the ensemble of r19 and r21 on the test set. The ensemble+ of (r4, r7 r12) was analyzed after test submission. Table TABREF9 (SLC) shows that our submission is ranked at 4th position.\n\nThe best performing model is the ensemble+ of (II and IV) from each of the folds 1-3, i.e., $|{\\mathcal {M}}|=6$ models to obtain predictions on test. Table TABREF9 (FLC) shows that our submission is ranked at", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "\n\nThe baseline is the M2M Transformer model trained on the mixture of six-way pseudo-parallel data generated by VII and the original parallel data.\n\nQuestion: what is the difference between the baseline and the new model?\n\nAnswer:[/INST]\n\nThe new model is the M2M Transformer model trained on the mixture of the generated pseudo-parallel data and the original parallel data.\n\nQuestion: what is the difference between the new model and the new model trained on the mixture of the generated pseudo-parallel data and the original parallel data?\n\nAnswer:[/INST]", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "\n\nAnswer: The paper explores the use of word embeddings to quantify semantic similarity and relatedness. Word embeddings are a type of distributional approach that learn a representation of a word by word co–occurrence matrix. The basic idea is that the neural network learns a series of weights (the hidden layer within the neural network) that either maximizes the probability of a word given its context, referred to as the continuous bag of words (CBOW) approach, or that maximizes the probability of the context given a word, referred to as the Skip–gram approach. These approaches have been", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["Unanswerable", "CFILT-preorder system"], "all_classes": null, "length": 2231}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Yes"], "all_classes": null, "length": 3035}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "\n\n### [INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nNeural networks have been successfully used to describe images with text using sequence-to-sequence models BIBREF0. However, the results are simple and dry captions which", "answers": ["generating a poem from images we use an existing actor-critic architecture, various types of sequence to sequence models"], "all_classes": null, "length": 1653}
{"pred": "\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer layer works better.\n\nAnswer: The transformer", "answers": ["Transformer over BERT (ToBERT)", "The transformer layer"], "all_classes": null, "length": 2655}
{"pred": "\n\nAnswer: Yes.\n\nAnswer: No.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "\n\nCyberbullying has been defined by the National Crime Prevention Council as the use of the Internet, cell phones or other devices to send or post text or images intended to hurt or embarrass another person. Various studies have estimated that between to 10% to 40% of internet users are victims of cyberbullying BIBREF0 . Effects of cyberbullying can range from temporary anxiety to suicide BIBREF1 . Many high profile incidents have emphasized the prevalence of cyberbullying on social media. Most recently in October 201", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "\n\nThe new context representation is obtained by concatenating the left context, the left entity and the middle context.\n\nAnswer:[/INST]\n\nThe new context representation is obtained by concatenating the left context, the left entity and the middle context.\n\nAnswer:[/INST]\n\nThe new context representation is obtained by concatenating the left context, the left entity and the middle context.\n\nAnswer:[/INST]\n\nThe new context representation is obtained by concatenating the left context, the left entity and the middle context.\n\nAnswer:[/INST]\n\nThe new context representation is obtained", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "\n\nAnswer: There are 11 different types of entities in the dataset.\n\nQuestion: What is the most common type of entity in the dataset?\n\nAnswer:[/INST]\n\nAnswer: The most common type of entity in the dataset is \"PERSON\".\n\nQuestion: What is the least common type of entity in the dataset?\n\nAnswer:[/INST]\n\nAnswer: The least common type of entity in the dataset is \"LOCATION\".\n\nQuestion: What is the most common type of entity in the dataset?\n\nAnswer:[/INST]\n\nAnswer: The most", "answers": ["OurNepali contains 3 different types of entities, ILPRL contains 4 different types of entities", "three"], "all_classes": null, "length": 2851}
{"pred": "\n\nAnswer: The resulting annotated data is of higher quality.\n\nQuestion: How much higher quality is the resulting annotated data?\n\nAnswer:[/INST]\n\nAnswer: The resulting annotated data is of higher quality.\n\nQuestion: How much higher quality is the resulting annotated data?\n\nAnswer:[/INST]\n\nAnswer: The resulting annotated data is of higher quality.\n\nQuestion: How much higher quality is the resulting annotated data?\n\nAnswer:[/INST]\n\nAnswer: The resulting annotated data is of higher quality.\n\nQuestion: How much", "answers": ["improvement when the difficult subset with expert annotations is mixed with the remaining crowd annotation is 3.5 F1 score, much larger than when a random set of expert annotations are added"], "all_classes": null, "length": 4399}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "\n\n[INST]\n\nAnswer: The article states that the authors achieve state of the art results on the English-German dataset.\n\nQuestion: What is the main difference between the base and deliberation models?\n\nAnswer:[/INST]\n\n[INST]\n\nAnswer: The main difference between the base and deliberation models is that the deliberation models use a second-pass decoder to improve the first-pass decoder outputs.\n\nQuestion: What is the main difference between the base+sum and base+att models?\n\nAnswer:[/INST]\n\n[INST]\n", "answers": ["the English-German dataset"], "all_classes": null, "length": 1833}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019"], "all_classes": null, "length": 3629}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/", "answers": ["BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21", "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26"], "all_classes": null, "length": 1452}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "\n\n[SECREF1]\n\n[SECREF2]\n\n[SECREF3]\n\n[SECREF4]\n\n[SECREF5]\n\n[SECREF6]\n\n[SECREF7]\n\n[SECREF8]\n\n[SECREF9]\n\n[SECREF10]\n\n[SECREF11]\n\n[SECREF12]\n\n[SECREF13]\n\n[SECREF14]\n\n[SECREF15]\n\n", "answers": ["BOW-Tags, BOW-KL(Tags), BOW-All, GloVe"], "all_classes": null, "length": 4658}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1687}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["CSAT dataset, 20 newsgroups, Fisher Phase 1 corpus", "CSAT dataset , 20 newsgroups, Fisher Phase 1 corpus"], "all_classes": null, "length": 2652}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nRecurrent neural networks (RNNs), including gated variants such as the long short-term memory (LSTM) BIBREF0 have become the standard model architecture for", "answers": ["the IMDb movie review dataset BIBREF17", "IMDb movie review"], "all_classes": null, "length": 3432}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nThe recently introduced BERT model BIBREF0 exhibits strong performance on several language understanding benchmarks. To what extent does it capture syntax-sensitive structures?\nRecent work", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1464}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["No"], "all_classes": null, "length": 1441}
{"pred": "\n\nAnswer: The invertibility condition is that the projection function is invertible.\n\nQuestion: What is the invertibility condition?\n\nAnswer:[/INST]\n\nAnswer: The invertibility condition is that the projection function is invertible.\n\nQuestion: What is the invertibility condition?\n\nAnswer:[/INST]\n\nAnswer: The invertibility condition is that the projection function is invertible.\n\nQuestion: What is the invertibility condition?\n\nAnswer:[/INST]\n\nAnswer: The invertibility condition is that the projection function is invertible.\n\nQuestion: What is", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "\n\n### 2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1", "answers": ["The resulting taxonomy of the framework is shown in Figure FIGREF10", "FIGREF10"], "all_classes": null, "length": 4958}
{"pred": "\n\nThe WikiSmall dataset has 89,042 sentence pairs, and the WikiLarge dataset has 296,402 sentence pairs.\n\n[/INST]\n\n[INST]\n\nAnswer: what are the sizes of both datasets?\n\nAnswer:[/INST]\n\nThe WikiSmall dataset has 89,042 sentence pairs, and the WikiLarge dataset has 296,402 sentence pairs.\n\n[/INST]\n\n[INST]\n\nAnswer: what are the sizes of both datasets", "answers": ["training set has 89,042 sentence pairs, and the test set has 100 pairs, training set contains 296,402, 2,000 for development and 359 for testing", "WikiSmall  89 142 sentence pair and  WikiLarge 298 761 sentence pairs. "], "all_classes": null, "length": 2266}
{"pred": "\n\nAnswer: The baselines are the following:\n\n1. Cascaded model: The cascaded model is a traditional pipeline model, where the ASR system is used to generate the acoustic features, and the MT system is used to generate the target text.\n\n2. End-to-end model: The end-to-end model is a model that directly translates the acoustic features into the target text without generating the intermediate text.\n\n3. Pre-training model: The pre-training model is a model that pre-trains the ASR and MT systems", "answers": ["Vanilla ST baseline, encoder pre-training, in which the ST encoder is initialized from an ASR model, decoder pre-training, in which the ST decoder is initialized from an MT model, encoder-decoder pre-training, where both the encoder and decoder are pre-trained, many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models, Triangle+pre-train: BIBREF18 DBLP:conf/naacl/AnastasopoulosC18 proposed a triangle multi-task strategy for speech translation", "Vanilla ST baseline, Pre-training baselines, Multi-task baselines, Many-to-many+pre-training, Triangle+pre-train", "Vanilla ST baseline: The vanilla ST BIBREF9 has only a speech encoder and a decoder. It is trained from scratch on the ST-TED corpus.\n\nPre-training baselines: We conduct three pre-training baseline experiments: 1) encoder pre-training, in which the ST encoder is initialized from an ASR model; 2) decoder pre-training, in which the ST decoder is initialized from an MT model; and 3) encoder-decoder pre-training, where both the encoder and decoder are pre-trained. The ASR model has the same architecture with vanilla ST model, trained on the mixture of ST-TED and TED-LIUM2 corpus. The MT model has a text encoder and decoder with the same architecture of which in TCEN. It is first trained on WMT data (out-of-domain) and then fine-tuned on in-domain data.\n\nMulti-task baselines: We also conduct three multi-task baseline experiments including one-to-many setting, many-to-one setting, and many-to-many setting. In the first two settings, we train the model with $\\alpha _{st}=0.75$ while $\\alpha _{asr}=0.25$ or $\\alpha _{mt}=0.25$. For many-to-many setting, we use $\\alpha _{st}=0.6, \\alpha _{asr}=0.2$ and $\\alpha _{mt}=0.2$.. For MT task, we use only in-domain data.\n\nMany-to-many+pre-training: We train a many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models. "], "all_classes": null, "length": 4704}
{"pred": "\n\nEnglish\n\nQuestion: What is the main focus of this paper?\n\nAnswer:[/INST]\n\nThe challenges of imbalanced classification—in which the proportion of elements in each class for a classification task significantly differ—and of the ability to generalise on dissimilar data have remained important problems in Natural Language Processing (NLP) and Machine Learning in general. Popular NLP tasks including sentiment analysis, propaganda detection, and event extraction from social media are all examples of imbalanced classification problems. In each case the number of elements in one of the classes (e.g. negative sentiment", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 4513}
{"pred": "\n\nThe models used in the experiment are:\n\n1. Linear SVM\n2. BiLSTM\n3. CNN\n\nQuestion: What is the performance of the models?\n\nAnswer:[/INST]\n\nThe performance of the models is:\n\n1. Linear SVM: F1 score of 0.79\n2. BiLSTM: F1 score of 0.80\n3. CNN: F1 score of 0.80\n\nQuestion: What is the performance of the models on the target identification task?\n\nAnswer:[/INST]", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Pretrained word embeddings  were not used", "GloVe, Edinburgh embeddings BIBREF14, Emoji embeddings BIBREF16"], "all_classes": null, "length": 1771}
{"pred": "\n\nAnswer:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the new dataset are as follows:\n\nTheir results on the", "answers": ["average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time"], "all_classes": null, "length": 2666}
{"pred": "\n\nAnswer: The combination of rewards for reinforcement learning is the combination of the irony reward, the sentiment reward, and the content reward.\n\nQuestion: What is the irony reward?\n\nAnswer:[/INST]\n\nAnswer: The irony reward is a reward for the irony accuracy of the generated sentence.\n\nQuestion: What is the sentiment reward?\n\nAnswer:[/INST]\n\nAnswer: The sentiment reward is a reward for the sentiment preservation of the generated sentence.\n\nQuestion: What is the content reward?\n\nAnswer:[/INST]\n\nAnswer", "answers": ["irony accuracy, sentiment preservation", " irony accuracy and sentiment preservation"], "all_classes": null, "length": 4592}
{"pred": "\n\nAnswer: The authors demonstrate that their model does not work well with Shakespeare style transfer for the given painting. This happens when the style transfer dataset does not have similar words in the training set of sentences. A solution would be to expand the style transfer dataset, for a better representation of the poem data.\n\nAnswer: The authors demonstrate that their model does not work well with Shakespeare style transfer for the given painting. This happens when the style transfer dataset does not have similar words in the training set of sentences. A solution would be to expand the style transfer dataset, for a better representation of the poem data.\n\nAnswer:", "answers": ["Since we do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transfer", "we do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transfer as shown in Figure FIGREF12 for \"Starry Night\" with a low average content score"], "all_classes": null, "length": 1651}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Affective Text, Fairy Tales, ISEAR", " Affective Text dataset, Fairy Tales dataset, ISEAR dataset"], "all_classes": null, "length": 3390}
{"pred": "\n\nAnswer:\n\nTheir distribution results were:\n\n1. The number of favourites was not statistically different between accounts spreading fake news and those not spreading fake news.\n\n2. The number of hashtags used was not statistically different between accounts spreading fake news and those not spreading fake news.\n\n3. The number of mentions was not statistically different between accounts spreading fake news and those not spreading fake news.\n\n4. The presence of media was not statistically different between accounts spreading fake news and those not spreading fake news.\n\n5.", "answers": ["Distributions of Followers, Friends and URLs are significantly different between the set of tweets containing fake news and those non containing them, but for Favourites, Mentions, Media, Retweets and Hashtags they are not significantly different"], "all_classes": null, "length": 3164}
{"pred": "\n\nThe dataset of hashtags is sourced from Twitter. We crawled the tweets from the year 2010 and extracted the hashtags from them.\n\nQuestion: How is the dataset of hashtags annotated?\n\nAnswer:[/INST]\n\nThe dataset of hashtags is annotated by human annotators. The annotators are given a set of hashtags and are asked to segment them into meaningful words.\n\nQuestion: How is the dataset of hashtags annotated?\n\nAnswer:[/INST]\n\nThe dataset of hashtags", "answers": ["1,268 randomly selected tweets in the Stanford Sentiment Analysis Dataset BIBREF36, all 12,594 unique English hashtags and their associated tweets from the same Stanford dataset", "Stanford Sentiment Analysis Dataset BIBREF36"], "all_classes": null, "length": 3756}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "\n\nWord subspace can represent the context of the text.\n\nQuestion: What is the main contribution of this work?\n\nAnswer:[/INST]\n\nThe main contribution of this work is the novel concept of word subspace, which can be used to represent the context of the text.\n\nQuestion: What is the difference between the bag-of-words model and the word subspace model?\n\nAnswer:[/INST]\n\nThe bag-of-words model is a model that represents a text as a set of words, while the word subspace model is a model that represents a text as", "answers": ["Word vectors, usually in the context of others within the same class"], "all_classes": null, "length": 5151}
{"pred": "\n\nAnswer: The baseline model is a linear SVM.\n\nQuestion: What is the performance of the baseline model?\n\nAnswer:[/INST]\n\nAnswer: The performance of the baseline model is P=0.12.\n\nQuestion: What is the performance of the proposed approach?\n\nAnswer:[/INST]\n\nAnswer: The performance of the proposed approach is P=0.66.\n\nQuestion: What is the performance of the proposed approach for the years 2009-2012?\n\nAnswer:[/INST]\n\nAnswer", "answers": ["For Article-Entity placement, they consider two baselines: the first one using only salience-based features, and the second baseline checks if the entity appears in the title of the article. \n\nFor Article-Section Placement, they consider two baselines: the first picks the section with the highest lexical similarity to the article, and the second one picks the most frequent section.", "B1. The first baseline uses only the salience-based features by Dunietz and Gillick BIBREF11 ., B2. The second baseline assigns the value relevant to a pair INLINEFORM0 , if and only if INLINEFORM1 appears in the title of INLINEFORM2 .\n\n, S1: Pick the section from template INLINEFORM0 with the highest lexical similarity to INLINEFORM1 : S1 INLINEFORM2, S2: Place the news into the most frequent section in INLINEFORM0"], "all_classes": null, "length": 7891}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2000}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2410}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": [" high-quality datasets  from SemEval-2016 “Sentiment Analysis in Twitter” task", " SemEval-2016 “Sentiment Analysis in Twitter”"], "all_classes": null, "length": 2738}
{"pred": "\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large BERT.\n\nAnswer: They use large B", "answers": ["small BERT", "small BERT"], "all_classes": null, "length": 1999}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["No", "No"], "all_classes": null, "length": 6391}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3472}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Answer with content missing: (Table 3) Best author's model B-M average micro f-score is 0.409, 0.459, 0.411 on Affective, Fairy Tales and ISEAR datasets respectively. "], "all_classes": null, "length": 3410}
{"pred": "\n\nAnswer: The tagging scheme employed is the INLINEFORM0 scheme.\n\nQuestion: What is the tagging scheme employed?\n\nAnswer:[/INST]\n\nAnswer: The tagging scheme employed is the INLINEFORM1 scheme.\n\nQuestion: What is the tagging scheme employed?\n\nAnswer:[/INST]\n\nAnswer: The tagging scheme employed is the INLINEFORM2 scheme.\n\nQuestion: What is the tagging scheme employed?\n\nAnswer:[/INST]\n\nAnswer: The tagging scheme employed is the INLINEFORM3 scheme.\n\nQuestion", "answers": ["A new tagging scheme that tags the words before and after the pun as well as the pun words.", "a new tagging scheme consisting of three tags, namely { INLINEFORM0 }"], "all_classes": null, "length": 2974}
{"pred": "\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\nAnswer: No.\n\n", "answers": ["No", "No"], "all_classes": null, "length": 2413}
{"pred": "\n\nRobustness of a model is defined as the ability of the model to perform well in the presence of noise.\n\nAnswer:[/INST]\n\nRobustness of a model is defined as the ability of the model to perform well in the presence of noise.\n\nAnswer:[/INST]\n\nRobustness of a model is defined as the ability of the model to perform well in the presence of noise.\n\nAnswer:[/INST]\n\nRobustness of a model is defined as the ability of the model to perform well in the presence of noise.\n\nAnswer:[/INST]", "answers": ["ability to accurately classify texts even when the amount of prior knowledge for different classes is unbalanced, and when the class distribution of the dataset is unbalanced", "Low sensitivity to bias in prior knowledge"], "all_classes": null, "length": 3609}
{"pred": "\n\n[SECREF1]\n\n[SECREF2]\n\n[SECREF3]\n\n[SECREF4]\n\n[SECREF5]\n\n[SECREF6]\n\n[SECREF7]\n\n[SECREF8]\n\n[SECREF9]\n\n[SECREF10]\n\n[SECREF11]\n\n[SECREF12]\n\n[SECREF13]\n\n[SECREF14]\n\n[SECREF15]\n\n", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "\n\nThe proposed method improves the F1 score for NER task for English and Chinese datasets.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score for NER task for English and Chinese datasets.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score for NER task for English and Chinese datasets.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score for NER task for English and Chinese datasets.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score for NER task for", "answers": ["English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively, Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectively", "For English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively., huge performance boosts on Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectively"], "all_classes": null, "length": 3586}
{"pred": "\n\n[INST]You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nArticle: Introduction\nModelling the relationship between sequences is extremely significant in most retrieval or classification problems involving two sequences. Traditionally, in Siamese networks, Hadamard product or concatenation have", "answers": ["Task 1: Quora Duplicate Question Pair Detection, Task 2: Ranking questions", "Quora Duplicate Question Pair Detection, Ranking questions in Bing's People Also Ask"], "all_classes": null, "length": 2577}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer", "answers": ["Various tree structured neural networks including variants of Tree-LSTM, Tree-based CNN, RNTN, and non-tree models including variants of LSTMs, CNNs, residual, and self-attention based networks", "Sentence classification baselines: RNTN (Socher et al. 2013), AdaMC-RNTN (Dong et al. 2014), TE-RNTN (Qian et al. 2015), TBCNN (Mou et al. 2015), Tree-LSTM (Tai, Socher, and Manning 2015), AdaHT-LSTM-CM (Liu, Qiu, and Huang 2017), DC-TreeLSTM (Liu, Qiu, and Huang 2017), TE-LSTM (Huang, Qian, and Zhu 2017), BiConTree (Teng and Zhang 2017), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), TreeNet (Cheng et al. 2018), CNN (Kim 2014), AdaSent (Zhao, Lu, and Poupart 2015), LSTM-CNN (Zhou et al. 2016), byte-mLSTM (Radford, Jozefowicz, and Sutskever 2017), BCN + Char + CoVe (McCann et al. 2017), BCN + Char + ELMo (Peters et al. 2018). \nStanford Natural Language Inference baselines: Latent Syntax Tree-LSTM (Yogatama et al. 2017), Tree-based CNN (Mou et al. 2016), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), NSE (Munkhdalai and Yu 2017), Reinforced Self- Attention Network (Shen et al. 2018), Residual stacked encoders: (Nie and Bansal 2017), BiLSTM with generalized pooling (Chen, Ling, and Zhu 2018)."], "all_classes": null, "length": 4781}
{"pred": "\n\nKB relation detection is a key step in KBQA and is significantly different from general relation extraction tasks. We propose a novel KB relation detection model, HR-BiLSTM, that performs hierarchical matching between questions and KB relations. Our model outperforms the previous methods on KB relation detection tasks and allows our KBQA system to achieve state-of-the-arts. For future work, we will investigate the integration of our HR-BiLSTM into end-to-end systems. For example, our model could be integrated into the decoder in B", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\n", "answers": ["name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)"], "all_classes": null, "length": 2655}
{"pred": "\n\n[INST]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=0cm]\n\n[leftmargin=", "answers": ["spot patterns by just looking at a collection of images, tag all descriptions with part-of-speech information, I applied Louvain clustering", "Looking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging"], "all_classes": null, "length": 2204}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["English, French, German ", "French, English, Spanish, Italian, Portuguese, Hebrew, Arabic"], "all_classes": null, "length": 2285}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["Stacked LSTMs, Cell-aware Stacked LSTMs, Sentence Encoders, Top-layer Classifiers"], "all_classes": null, "length": 3210}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 6169}
{"pred": "\n\nAnswer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"no\", or \"unanswerable\". Do not provide any explanation.\n\nAnswer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write \"unanswerable\". If the question is a yes/no question, answer \"yes\", \"", "answers": ["LSA, TextRank, LexRank and ILP-based summary.", "LSA, TextRank, LexRank"], "all_classes": null, "length": 3045}
{"pred": "\n\nThe previous state of the art for this task was to use a bag-of-words representation of the thread and a classifier to predict intervention.\n\nAnswer:[/INST]\n\nThe previous state of the art for this task was to use a bag-of-words representation of the thread and a classifier to predict intervention.\n\nAnswer:[/INST]\n\nThe previous state of the art for this task was to use a bag-of-words representation of the thread and a classifier to predict intervention.\n\nAnswer:[/INST]\n\nThe previous state of the art", "answers": ["hLSTM", "hLSTM"], "all_classes": null, "length": 3725}
{"pred": "\n\nThe concept of message passing over graphs has been around for many years BIBREF0, BIBREF1, as well as that of graph neural networks (GNNs) BIBREF2, BIBREF3. However, GNNs have only recently started to be closely investigated, following the advent of deep learning. Some notable examples include BIBREF4, BIBREF5, BIBREF6, BIBREF7, BIBREF8, BIBREF9, BIBREF10, BIBREF11, BIBREF12. These approaches are known as spectral", "answers": ["Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets."], "all_classes": null, "length": 4180}
{"pred": "\n\nAnswer: The corpus used for the task is the DTA corpus, which is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century.\n\nAnswer: The corpus used for the task is the DTA corpus, which is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German containing texts from the 16th to the 20th century.\n\nAnswer: The cor", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "\n\nAnswer: Kannada, Hindi, Telugu, Malayalam, Bengali, and English.\n\nAnswer: Kannada, Hindi, Telugu, Malayalam, Bengali, and English.\n\nAnswer: Kannada, Hindi, Telugu, Malayalam, Bengali, and English.\n\nAnswer: Kannada, Hindi, Telugu, Malayalam, Bengali, and English.\n\nAnswer: Kannada, Hindi, Telugu, Malayalam, Bengali, and", "answers": ["Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam", "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)"], "all_classes": null, "length": 2453}
{"pred": "\n\n### 2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1", "answers": ["Table TABREF6, Table TABREF8", "when testing on English, the F1 score of the model training on Chinese (Zh) is 53.8,  F1 score is only 44.1 for the model training on Zh-En"], "all_classes": null, "length": 2492}
{"pred": "\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\nAnswer: The proposed model outperforms the baselines by a significant margin.\n\n", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.\n\nAnswer: ARAML can improve the performance of text generation models.", "answers": ["ARAM has achieved improvement over all baseline methods using reverese perplexity and  slef-BLEU metric.  The maximum reverse perplexity improvement 936,16 is gained for EMNLP2017  WMT  dataset and  48,44 for COCO dataset.", "Compared to the baselines, ARAML does not do better in terms of perplexity on COCO and EMNLP 2017 WMT datasets, but it does by up to 0.27 Self-BLEU points on COCO and 0.35 Self-BLEU on EMNLP 2017 WMT. In terms of Grammaticality and Relevance, it scores better than the baselines on up to 75.5% and 73% of the cases respectively."], "all_classes": null, "length": 3796}
{"pred": "\n\nThe authors present evidence that the model can capture some biases in data annotation and collection by examining the results of the model. The authors found that the model was able to correctly classify some tweets that were annotated as hate speech, but were actually offensive or neutral. This suggests that the model was able to capture the biases in the data annotation and collection process.\n\nAnswer:[/INST]\n\nThe authors present evidence that the model can capture some biases in data annotation and collection by examining the results of the model. The authors found that the model was able to correctly classify some twe", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "\n\nAnswer: The dataset is 100000 words.\n\nQuestion: What is the size of the dataset?\n\nAnswer:[/INST]\n\nAnswer: The dataset is 100000 words.\n\nQuestion: What is the size of the dataset?\n\nAnswer:[/INST]\n\nAnswer: The dataset is 100000 words.\n\nQuestion: What is the size of the dataset?\n\nAnswer:[/INST]\n\nAnswer: The dataset is 100000 words.\n\nQuestion: What is the", "answers": ["Dataset contains 3606 total sentences and 79087 total entities.", "ILPRL contains 548 sentences, OurNepali contains 3606 sentences"], "all_classes": null, "length": 2843}
{"pred": "\n\nThe proposed method improves the F1 score by +0.58 for MRPC and +0.73 for QQP.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score by +0.58 for MRPC and +0.73 for QQP.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score by +0.58 for MRPC and +0.73 for QQP.\n\nAnswer:[/INST]\n\nThe proposed method improves the F1 score by +0", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "\n\nThe datasets used in this work are the same as those used in BIBREF0 . The data is available at the following URL: http://www.cs.toronto.edu/~rjones/data/\n\nQuestion: What is the neural network architecture?\n\nAnswer:[/INST]\n\nThe neural network architecture is a bi-LSTM encoder with a linear decoder. The encoder is a bi-LSTM with 1024 hidden units, and the decoder is a linear layer with 1024 units. The encoder and decoder are connected", "answers": ["Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)", "the ERP data: BIBREF0"], "all_classes": null, "length": 1971}
{"pred": "\n\nThe subjects were presented with a series of stimuli, including words, phonemes, and syllables, and were asked to imagine saying the words, phonemes, and syllables.\n\nAnswer:[/INST]\n\nThe subjects were presented with a series of stimuli, including words, phonemes, and syllables, and were asked to imagine saying the words, phonemes, and syllables.\n\nAnswer:[/INST]\n\nThe subjects were presented with a series of stimuli, including words, phonemes, and syllables, and were asked", "answers": ["7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)", "KARA ONE BIBREF17 , composed of multimodal data for stimulus-based, imagined and articulated speech state corresponding to 7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)"], "all_classes": null, "length": 2379}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN"], "all_classes": null, "length": 4085}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT),  Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN)", "Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT), CNN, RNN"], "all_classes": null, "length": 2074}
{"pred": "\n\nThe article describes a sequence to sequence model that is pre-trained on a large corpus of text. The model is then fine-tuned on a smaller corpus of text. The article does not specify the architecture of the sequence to sequence model.\n\nQuestion: What is the size of the training data?\n\nAnswer:[/INST]\n\nThe article does not specify the size of the training data.\n\nQuestion: What is the size of the test data?\n\nAnswer:[/INST]\n\nThe article does not specify the size of the test data.\n\nQuestion: What", "answers": ["uni-directional model to augment the decoder", "bi-directional language model to augment the sequence to sequence encoder ,  uni-directional model to augment the decoder"], "all_classes": null, "length": 1914}
{"pred": "\n\nThe weights are dynamically adjusted by the dynamic weight adjusting strategy. The strategy associates each training example with a weight in proportion to $(1-p)$, and this weight dynamically changes as training proceeds. This strategy helps to deemphasize confident examples during training as their $p$ approaches the value of 1, makes the model attentive to hard-negative examples, and thus alleviates the dominating effect of easy-negative examples.\n\nAnswer: How does the proposed method work?\n\nAnswer:[/INST]\n\nThe proposed method works by replacing the standard cross-entropy loss", "answers": ["One can think $(1-p_{i1})$ as a weight associated with each example, which changes as training proceeds. The intuition of changing $p_{i1}$ to $(1-p_{i1}) p_{i1}$ is to push down the weight of easy examples. For easy examples whose probability are approaching 0 or 1, $(1-p_{i1}) p_{i1}$ makes the model attach significantly less focus to them. Figure FIGREF23 gives gives an explanation from the perspective in derivative: the derivative of $\\frac{(1-p)p}{1+(1-p)p}$ with respect to $p$ approaches 0 immediately after $p$ approaches 0, which means the model attends less to examples once they are correctly classified.", "associates each training example with a weight in proportion to $(1-p)$, and this weight dynamically changes as training proceeds"], "all_classes": null, "length": 3640}
{"pred": "\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\n", "answers": ["Reward of 11.8 for the A2C-chained model, 41.8 for the KG-A2C-chained model, 40 for A2C-Explore and 44 for KG-A2C-Explore.", "KG-A2C-chained and KG-A2C-Explore both pass the bottleneck of a score of 40"], "all_classes": null, "length": 2443}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer", "answers": ["Bayesian model of garg2012unsupervised as our base monolingual model"], "all_classes": null, "length": 3701}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable", "Original transcription was labeled with additional labels in [] brackets with nonstandard pronunciation."], "all_classes": null, "length": 3018}
{"pred": "\n\nA semicharacter architecture is a type of neural network architecture that uses a combination of characters and subwords to represent words. This type of architecture is often used in natural language processing (NLP) tasks such as machine translation, text classification, and sentiment analysis.\n\nIn a semicharacter architecture, each word is represented as a sequence of characters and subwords. A character is a single letter or symbol, while a subword is a sequence of characters that is not a word. For example, the word \"hello\" would be represented as a sequence of characters and subwords, such as \"h\",", "answers": ["A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal characters", "processes a sentence of words with misspelled characters, predicting the correct words at each step"], "all_classes": null, "length": 4186}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish and Swedish", "Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish , Swedish"], "all_classes": null, "length": 2697}
{"pred": "\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n[/INST]\n\n[INST]\n\n", "answers": ["NCEL consistently outperforms various baselines with a favorable generalization ability"], "all_classes": null, "length": 4113}
{"pred": "Yes\n\nAnswer:[/INST]No\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswerable\n\nAnswer:[/INST]Unanswer", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "\n\nAnswer: The baseline used was the system by Rei2016, trained on the same FCE dataset.\n\nAnswer: The baseline used was the system by Rei2016, trained on the same FCE dataset.\n\nAnswer: The baseline used was the system by Rei2016, trained on the same FCE dataset.\n\nAnswer: The baseline used was the system by Rei2016, trained on the same FCE dataset.\n\nAnswer: The baseline used was the system by Rei2016, trained", "answers": ["error detection system by Rei2016", "error detection system by Rei2016"], "all_classes": null, "length": 2132}
{"pred": "\n\nThe annotated clinical notes were obtained from the i2b2/VA dataset.\n\n[/INST]\n\n[INST]\n\nArticle: Introduction\nMedical search engines are an essential component for many online medical applications, such as online diagnosis systems and medical document databases. A typical online diagnosis system, for instance, relies on a medical search engine. The search engine takes as input a user query that describes some symptoms and then outputs clinical concept entries that provide relevant information to assist in diagnosing the problem. One challenge medical search engines face is the segmentation of individual clinical", "answers": ["clinical notes from the CE task in 2010 i2b2/VA", "clinical notes from the CE task in 2010 i2b2/VA "], "all_classes": null, "length": 3432}
{"pred": "\n\nMasking words in the decoder is helpful because it forces the model to generate a summary that is more natural and coherent. By masking words, the model is forced to generate a summary that is more focused on the important information and less on the irrelevant information. This helps to improve the quality of the generated summary and makes it more readable.\n\nQuestion: How does the refine decoder help the model to generate more natural summaries?\n\nAnswer:[/INST]\n\nThe refine decoder helps the model to generate more natural summaries by providing additional information about the context of the words in", "answers": ["ecause this process is similar to the cloze task in BERT's pre-train process, therefore by using the ability of the contextual language model the decoder can generate more fluent and natural sequences."], "all_classes": null, "length": 3919}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable", " Paraphrase Database (PPDB) ,  book corpus", "Unanswerable"], "all_classes": null, "length": 1902}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 2108}
{"pred": "\nThe dataset is annotated with 9,473 annotations for 9,300 tweets. Each tweet is annotated as no evidence of depression (e.g., “Citizens fear an economic depression\") or evidence of depression (e.g., “depressed over disappointment\"). If a tweet is annotated evidence of depression, then it is further annotated with one or more depressive symptoms, for example, depressed mood (e.g., “feeling down in the dumps\"), disturbed sleep (e.g., “another", "answers": ["no evidence of depression, depressed mood, disturbed sleep, fatigue or loss of energy", "The annotations are based on evidence of depression and further annotated by the depressive symptom if there is evidence of depression"], "all_classes": null, "length": 1947}
{"pred": "\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/INST]\n\nAnswer:\n\n[/", "answers": ["BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800", "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800"], "all_classes": null, "length": 2800}
{"pred": "\n\nThe training data was translated by using the machine translation platform Apertium BIBREF5 .\n\nQuestion: How was the data augmented?\n\nAnswer:[/INST]\n\nThe training data was augmented by translating the English datasets into Spanish.\n\nQuestion: How was semi-supervised learning applied?\n\nAnswer:[/INST]\n\nThe semi-supervised learning approach was applied by using the DISC BIBREF0 corpus.\n\nQuestion: How was the data ensembling applied?\n\nAnswer:[/INST]\n\nThe data ensembling was applied", "answers": ["using the machine translation platform Apertium ", "machine translation platform Apertium BIBREF5"], "all_classes": null, "length": 2423}
{"pred": "\n\nThe authors used a content-based classifier to predict the industry of a user.\n\nQuestion: What is the difference between a content-based classifier and a user-based classifier?\n\nAnswer:[/INST]\n\nA content-based classifier is based on the content of the text, while a user-based classifier is based on the user's profile metadata.\n\nQuestion: What is the difference between a content-based classifier and a user-based classifier?\n\nAnswer:[/INST]\n\nA content-based classifier is based on the content of the", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "\n\nAnswer: The baseline for this task was a simple logistic regression model trained on the training set.\n\nQuestion: What is the difference between the sentence-level classification and the fragment-level classification?\n\nAnswer:[/INST]\n\nAnswer: The sentence-level classification task is about identifying propaganda in a sentence, while the fragment-level classification task is about identifying propaganda in a fragment of text.\n\nQuestion: What is the difference between the sentence-level classification and the fragment-level classification?\n\nAnswer:[/INST]\n\nAnswer: The sentence-level classification task", "answers": ["The baseline system for the SLC task is a very simple logistic regression classifier with default parameters. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly.", "SLC task is a very simple logistic regression classifier, FLC task generates spans and selects one of the 18 techniques randomly"], "all_classes": null, "length": 3001}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF."], "all_classes": null, "length": 2991}
{"pred": "\n\nThe political bias of different sources is included in the model by using a binary classification task. The model is trained on a dataset of mainstream news articles, and the political bias of each source is labeled as left-biased or right-biased. The model is then tested on a dataset of disinformation news articles, and the political bias of each source is labeled as left-biased or right-biased. The model is then trained on the dataset of disinformation news articles, and the political bias of each source is labeled as left-biased or right-biased.\n\nQuestion:", "answers": ["By assigning a political bias label to each news article and training only on left-biased or right-biased outlets of both disinformation and mainstream domains", "we also account for political biases inherent to different news sources, referring to the procedure proposed in BIBREF2 to label different outlets. Overall we show that we are able to classify credible vs non-credible diffusion networks (and consequently news articles) with high accuracy (AUROC up to 94%), even when accounting for the political bias of sources (and training only on left-biased or right-biased articles). We observe that the layer of mentions alone conveys useful information for the classification, denoting a different usage of this functionality when sharing news belonging to the two news domains. We also show that most discriminative features, which are relative to the breadth and depth of largest cascades in different layers, are the same across the two countries."], "all_classes": null, "length": 4882}
{"pred": "\n\nThe ancient Chinese dataset comes from the ancient Chinese corpus which is collected by the National Center for Digital Humanities and Social Sciences Data (NCDHSSD).\n\nQuestion: What is the size of the dataset?\n\nAnswer:[/INST]\n\nThe dataset contains INLINEFORM0 1.24M bilingual sentence pairs.\n\nQuestion: What is the size of the training set?\n\nAnswer:[/INST]\n\nThe training set contains INLINEFORM0 0.46M bilingual sentence pairs.\n\nQuestion: What is the size of the test", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/INST]\n\nEnglish\n\nAnswer:[/", "answers": ["English", "English ", "English"], "all_classes": null, "length": 2240}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Answer with content missing: (Data section) Chinese with version 5.1 of the Chinese Penn Treebank (CTB)"], "all_classes": null, "length": 2545}
{"pred": "\n\nAnswer: The UTCNN model has 3 layers.\n\nQuestion: How many layers does the UTCNN model have?\n\nAnswer:[/INST]\n\nAnswer: The UTCNN model has 3 layers.\n\nQuestion: How many layers does the UTCNN model have?\n\nAnswer:[/INST]\n\nAnswer: The UTCNN model has 3 layers.\n\nQuestion: How many layers does the UTCNN model have?\n\nAnswer:[/INST]\n\nAnswer: The UTCNN model has 3 layers.\n\nQuestion: How many layers does the UTCNN model have", "answers": ["eight layers"], "all_classes": null, "length": 4487}
{"pred": "\n\nThe dataset used in this paper is the Flickr dataset.\n\nQuestion: what is the dataset used in this paper?\n\nAnswer:[/INST]\n\nThe dataset used in this paper is the Flickr dataset.\n\nQuestion: what is the dataset used in this paper?\n\nAnswer:[/INST]\n\nThe dataset used in this paper is the Flickr dataset.\n\nQuestion: what is the dataset used in this paper?\n\nAnswer:[/INST]\n\nThe dataset used in this paper is the Flickr dataset.\n\nQuestion: what is the dataset", "answers": [" the same datasets as BIBREF7", "same datasets as BIBREF7"], "all_classes": null, "length": 4661}
{"pred": "\n\nThe paper uses two datasets:\n\n1. MEDDOCAN: Medical Document Anonymization shared task dataset BIBREF3.\n\n2. NUBes BIBREF4, a corpus of real medical reports in Spanish.\n\n[/INST]\n\n[SECREF3]\n\n[SECREF4]\n\n[SECREF5]\n\n[SECREF6]\n\n[SECREF7]\n\n[SECREF8]\n\n[SECREF9]\n\n[SECREF10]\n\n[SECRE", "answers": ["MEDDOCAN, NUBes-PHI", "MEDDOCAN, NUBes "], "all_classes": null, "length": 4528}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Unanswerable"], "all_classes": null, "length": 3543}
{"pred": "\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer:\n\n[/INST]\n\n[INST]\n\nAnswer", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": "\n\nAnswer: Yes\n\nAnswer: No\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswerable\n\nAnswer: Unanswer", "answers": ["Yes", "No"], "all_classes": null, "length": 1910}
{"pred": "\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n[/INST]\n\n", "answers": ["Galatasaray, Fenerbahçe", "Galatasaray , Fenerbahçe "], "all_classes": null, "length": 2234}
{"pred": "\n\nAnswer: The irony is a kind of figurative language, which is widely used on social media BIBREF0 . The irony is defined as a clash between the intended meaning of a sentence and its literal meaning BIBREF1 . As an important aspect of language, irony plays an essential role in sentiment analysis BIBREF2 , BIBREF0 and opinion mining BIBREF3 , BIBREF4 .\n\nAlthough some previous studies focus on irony detection, little attention is paid to irony generation. As ironies can strengthen sentiments and express stronger emotions, we", "answers": ["Irony Classifier, Sentiment Classifier for Irony, Sentiment Classifier for Non-irony, transformation from ironic sentences to non-ironic sentences"], "all_classes": null, "length": 4600}
{"pred": "\n\nGaussian-masked directional multi-head attention is a variant of self-attention which is proposed in this paper. It is a kind of attention mechanism which is used to capture the representation of input sequences. The input of Gaussian-masked directional multi-head attention contains queries, keys, and values of input sequences. The attention is generated using queries and keys like Equation (DISPLAY_FORM11). Structure of Gaussian-masked directional multi-head attention allows the self-attention layer generate the representation of sentences at once and contain the information of the sentence which is different from", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Facebook status update messages", "Facebook status update messages"], "all_classes": null, "length": 4005}
{"pred": "\n\nThe baseline features are the following:\n\n1. The number of words in the sentence.\n\n2. The number of characters in the sentence.\n\n3. The number of unique words in the sentence.\n\n4. The number of unique characters in the sentence.\n\n5. The number of words in the sentence that are not in the vocabulary of the word2vec model.\n\n6. The number of characters in the sentence that are not in the vocabulary of the word2vec model.\n\n7. The number of unique words in the sentence that are", "answers": [" The features extracted from CNN."], "all_classes": null, "length": 4855}
{"pred": "\n\nThe hyperparameters varied in the experiments on the four tasks are:\n\n1. The number of clusters (INLINEFORM0 )\n\n2. The number of clusters (INLINEFORM1 )\n\n3. The number of clusters (INLINEFORM2 )\n\n4. The number of clusters (INLINEFORM3 )\n\n5. The number of clusters (INLINEFORM4 )\n\n6. The number of clusters (INLINEFORM5 )\n\n7. The number of clusters (INLINEFORM6 )\n\n8. The number of clusters (INLINEFORM7 )\n", "answers": ["number of clusters, seed value in clustering, selection of word vectors, window size and dimension of embedding", "different number of clusters, different embeddings"], "all_classes": null, "length": 2753}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["column Ens Test in Table TABREF19"], "all_classes": null, "length": 2424}
{"pred": "\nThe corpus contains 53 documents, which contain an average number of 156.1 sentences per document, each with 19.55 tokens on average. The corpus comprises 8,275 sentences and 167,739 words in total. However, as mentioned above, only case presentation sections, headings and abstracts are annotated. The numbers of annotated entities are summarized in Table TABREF24.\n\nEntities can appear in a discontinuous way. We model this as a relation between two spans whichused in the embedding", "answers": ["8,275 sentences and 167,739 words in total", "The corpus comprises 8,275 sentences and 167,739 words in total."], "all_classes": null, "length": 2669}
{"pred": "\n\nAnswer: Yes, it is possible to convert a cloze-style questions to a naturally-looking questions.\n\nAnswer: No, it is not possible to convert a cloze-style questions to a naturally-looking questions.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable.\n\nAnswer: Unanswerable", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2764}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["text classification for themes including sentiment, web-page, science, medical and healthcare"], "all_classes": null, "length": 3591}
{"pred": "\n\nAnswer:\n\nTheir model is compared to the following methods:\n\n1. The Li and Roth model (BIBREF6 )\n2. The Kim model (BIBREF28 )\n3. The CNN model (BIBREF28 )\n4. The hypernym expansion model (BIBREF24 )\n5. The topic word model (BIBREF24 )\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\n", "answers": ["bag-of-words model, CNN"], "all_classes": null, "length": 5838}
{"pred": "\n\nThe training sets of these versions of ELMo are larger than the previous ones.\n\nAnswer:[/INST]\n\nThe training sets of these versions of ELMo are larger than the previous ones.\n\nAnswer:[/INST]\n\nThe training sets of these versions of ELMo are larger than the previous ones.\n\nAnswer:[/INST]\n\nThe training sets of these versions of ELMo are larger than the previous ones.\n\nAnswer:[/INST]\n\nThe training sets of these versions of ELMo are larger than the previous ones.\n\nAnswer:[/INST]\n\nThe", "answers": ["By 14 times.", "up to 1.95 times larger"], "all_classes": null, "length": 3294}
{"pred": "\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\nAnswer: 1000\n\n", "answers": ["3606", "6946"], "all_classes": null, "length": 2835}
{"pred": "\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\nAnswer:[/INST]\n\n", "answers": ["MLP", "Eusboost, MWMOTE"], "all_classes": null, "length": 2474}
{"pred": "Yes.\n\nAnswer:[/INST]No.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]Unanswerable.\n\nAnswer:[/INST]", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3784}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4320}
{"pred": "\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.6103\n\nAnswer: 0.", "answers": ["0.5115", "0.6103"], "all_classes": null, "length": 6810}
{"pred": "\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:", "answers": [" Wall Street Journal (WSJ) portion of the Penn Treebank", "Unanswerable"], "all_classes": null, "length": 4327}
{"pred": "\n\nThe authors evidence the claim that many engineers find it a big overhead to choose from multiple frameworks, models and optimization techniques by conducting a survey among engineers and identifying a spectrum of three typical personas. To satisfy the requirements of all the above three personas, the NLP toolkit has to be generic enough to cover as many tasks as possible. At the same time, it also needs to be flexible enough to allow alternative network architectures as well as customized modules. Therefore, the authors analyzed the NLP jobs submitted to a commercial centralized GPU cluster. Table TABREF11 showed that about 8", "answers": ["By conducting a survey among engineers", "Unanswerable"], "all_classes": null, "length": 1692}
{"pred": "\n\nAnswer:\n\nOn the SimpleQuestions dataset, our system achieves 93.3% top-1 accuracy, which is 1.3% higher than the previous state-of-the-art. On the WebQSP dataset, our system achieves 82.53% top-1 accuracy, which is 1.2% higher than the previous state-of-the-art.\n\nQuestion: What is the relation detection model?\n\nAnswer:[/INST]\n\nAnswer:\n\nThe relation detection model is a BiLSTM model with residual connections", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
